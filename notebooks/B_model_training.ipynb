{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook B: Model Training\n",
    "This notebook trains 6 algoritms to predict the production rates of 5 outputs of syngas fermentation based on the extracellular metabolite concentration, and gas composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing, sklearn.neural_network, sklearn.svm, sklearn.ensemble, sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data that was generated in notebook A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the rates data: 836 rows by 18 columns\n"
     ]
    }
   ],
   "source": [
    "rates_df = pd.read_csv(f'../data/rates_data.csv')\n",
    "print(f'Shape of the rates data: {rates_df.shape[0]} rows by {rates_df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: 657 rows by 18 columns\n",
      "Shape of the testing data: 179 rows by 18 columns\n"
     ]
    }
   ],
   "source": [
    "train_data = rates_df[rates_df.composition.isin([1,2,3,4,5,6,7])]\n",
    "test_data = rates_df[rates_df.composition.isin([8,9,10])]\n",
    "print(f'Shape of the training data: {train_data.shape[0]} rows by {train_data.shape[1]} columns')\n",
    "print(f'Shape of the testing data: {test_data.shape[0]} rows by {test_data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that generates the input and output arrays for scikit learn's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_arrays(data):\n",
    "\n",
    "    # prevent set with copy error\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # ML input\n",
    "    X = data_copy [[\n",
    "        'biomass (g/L)', 'ethanol (mM)', 'acetate (mM)', 'butanol (mM)', \n",
    "         'butyrate (mM)', 'N2', 'CO', 'CO2', 'H2', 'flow rate (mL/min)'\n",
    "    ]]\n",
    "    \n",
    "    # ML output\n",
    "    y = data_copy [[\n",
    "        'biomass rate', 'ethanol rate', 'acetate rate', 'butanol rate', 'butyrate rate'\n",
    "    ]]\n",
    " \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train X array: 657 rows by 10 columns\n",
      "Shape of the trainn y array: 657 rows by 5 columns\n",
      "Shape of the test X array: 179 rows by 10 columns\n",
      "Shape of the test y array: 179 rows by 5 columns\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_X_y_arrays(train_data)\n",
    "X_test, y_test = get_X_y_arrays(test_data)\n",
    "\n",
    "print(f'Shape of the train X array: {X_train.shape[0]} rows by {X_train.shape[1]} columns')\n",
    "print(f'Shape of the trainn y array: {y_train.shape[0]} rows by {y_train.shape[1]} columns')\n",
    "print(f'Shape of the test X array: {X_test.shape[0]} rows by {X_test.shape[1]} columns')\n",
    "print(f'Shape of the test y array: {y_test.shape[0]} rows by {y_test.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 30 different models (5 outputs each modeled with 6 algorithms)\n",
    "algorithms = neural network, support vector machine, random forest, support vector, neural net, lasso <br>\n",
    "outputs = acetate, biomass, butanol, butyrate, ethanol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a functions to generate neural network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_NN_fixed_n_layers(n_layers, n_neurons, neuron_step):\n",
    "    \"\"\"Generate NN hidden_layer_sizes of n_layers and up to n_neurons per layer \n",
    "    \"\"\"\n",
    "    # print (n_layers)\n",
    "    if n_layers == 1: \n",
    "        return [[i] for i in range(neuron_step, n_neurons+1, neuron_step)]\n",
    "    else:\n",
    "        pairs =  [  (i,  tail) for tail in gen_NN_fixed_n_layers(n_layers-1, n_neurons+1, neuron_step) for i in range(neuron_step, n_neurons+1, neuron_step) ]\n",
    "        return [[i]+ t for (i, t) in pairs]\n",
    "\n",
    "# print (gen_NN_fixed_n_layers(4, 10, 5))\n",
    "\n",
    "def gen_NN_uni(n_layers, n_neurons, layer_step, neuron_step):\n",
    "    \"\"\"Generate hidden layers of various number of layers and number of neurons \n",
    "    \"\"\" \n",
    "    various_NNs = [ gen_NN_fixed_n_layers(i , n_neurons, neuron_step) for i in range(2, n_layers+1, layer_step)]\n",
    "    return  functools.reduce(operator.add, various_NNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model configuration dictionary to guide ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test grid is used for debugging, should be replaced with full grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfgs = {\n",
    "        \"nn\":{\n",
    "            'estimator': sklearn.neural_network.MLPRegressor(shuffle=True),\n",
    "            # Test grid\n",
    "            'param_grid':   {\n",
    "                'activation': ['tanh', 'logistic', 'relu'], \n",
    "                'max_iter':   [400*i for i in range(1, 2)]\n",
    "            }\n",
    "            # Full grid\n",
    "            # 'param_grid':   {\n",
    "                # 'hidden_layer_sizes': gen_NN_uni(5, 100, 1, 10),  \n",
    "                # 'activation':         ['tanh', 'logistic', 'relu'], \n",
    "                # 'max_iter':           [400*i for i in range(1, 10, 2)]\n",
    "            # }                \n",
    "        },\n",
    "        \"svm_rbf\":{\n",
    "            'estimator': sklearn.svm.SVR(kernel='rbf'),\n",
    "            # Test grid\n",
    "            'param_grid':   {\n",
    "                'C':       [10**i for i in range(-1, 1)], \n",
    "                'epsilon': [10**i for i in range(-1, 1)],\n",
    "            }\n",
    "                # Full grid\n",
    "                # 'param_grid':   {\n",
    "                    # 'C':       [10**i for i in range(-5, 5)], \n",
    "                    # 'epsilon': [10**i for i in range(-5, 5)],\n",
    "                    # 'gamma':   [10**i for i in range(-5, 5)] # gamma gave me an error\n",
    "            # }\n",
    "        },\n",
    "        \"rf\":{\n",
    "            'estimator': sklearn.ensemble.RandomForestRegressor(),\n",
    "            # Test grid\n",
    "            'param_grid':   {\n",
    "                'n_estimators': [10*i for i in range(1, 2)],\n",
    "                'max_depth':     [2*i for i in range(1, 1+1)],\n",
    "            }\n",
    "            # Full grid \n",
    "            # 'param_grid':   {\n",
    "                # 'n_estimators': [10*i for i in range(1, 20)],\n",
    "                # 'max_depth':     [2*i for i in range(20)], \n",
    "                # 'max_samples': [0.05*i for i in range(1, 10+1)] # max samples gave me an error\n",
    "            # }\n",
    "        },\n",
    "        'en': {\n",
    "            'estimator': sklearn.linear_model.ElasticNet(),\n",
    "            # Test grid\n",
    "            'param_grid':   {\n",
    "                'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                'l1_ratio': [0.1, 1],\n",
    "            }\n",
    "            # Full grid \n",
    "            # 'param_grid': {\n",
    "                # 'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                # 'l1_ratio': [0.1, 1],\n",
    "            #}\n",
    "        },\n",
    "        'lasso': {\n",
    "            'estimator': sklearn.linear_model.Lasso(),\n",
    "            # Test grid\n",
    "            'param_grid':   {\n",
    "                'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "            }\n",
    "            # Full grid \n",
    "            # 'param_grid':   {\n",
    "                # 'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "            # }\n",
    "        },\n",
    "        'knn': {\n",
    "            'estimator': sklearn.neighbors.KNeighborsRegressor(),\n",
    "            # Test grid\n",
    "            'param_grid':   {\n",
    "                'algorithm': ['ball_tree', ],\n",
    "                'leaf_size': [4,5,6],\n",
    "                'n_neighbors': [2,3,4],\n",
    "                'weights': ['distance'],\n",
    "            }\n",
    "            # Full grid \n",
    "            # 'param_grid':   {\n",
    "                # 'algorithm': [0.0001, 0.001, 0.01, 0.1],\n",
    "                # 'leaf_size': [4, 5, 6],\n",
    "                # 'n_neighbors': [2, 3, 4],\n",
    "                # 'weights': ['distance'],\n",
    "            # }\n",
    "        },\n",
    "        \"bayesian\":{\n",
    "            'estimator': sklearn.linear_model.BayesianRidge(),\n",
    "            'param_grid':   {\n",
    "                'n_iter':  [300, 500], \n",
    "                'alpha_1': [10**i for i in range(-1, 1)], \n",
    "                'alpha_2': [10**i for i in range(-1, 1)], \n",
    "                'lambda_1': [10**i for i in range(-1, 1)], \n",
    "                'lambda_2': [10**i for i in range(-1, 1)], \n",
    "            }\n",
    "        },\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform grid search for each output and algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define a dictionary to hold results for all outputs\n",
    "trained_model_dictionary = {}\n",
    "\n",
    "# define a scaler to standardize the input values of all features between 0 and 1\n",
    "Scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X = Scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "# loop over outputs\n",
    "for index, output in enumerate(['biomass', 'ethanol', 'acetate', 'butanol', 'butyrate']):\n",
    "    print(f'{output}\\n')\n",
    "    \n",
    "    # define a dictionary to hold results for a single output\n",
    "    trained_models = {} \n",
    "    \n",
    "    # loop over models\n",
    "    for model_name, model_conf in model_cfgs.items():\n",
    "        print (model_name)\n",
    "        \n",
    "        # define grid search parameters\n",
    "        search = sklearn.model_selection.GridSearchCV(\n",
    "            estimator = model_conf[\"estimator\"], \n",
    "            param_grid = model_conf[\"param_grid\"], \n",
    "            scoring = \"r2\",\n",
    "            refit = True,\n",
    "            cv = sklearn.model_selection.ShuffleSplit(n_splits=10, test_size=0.1, random_state=0), \n",
    "            n_jobs=30, # This is a limitation of the server I am using. -gr\n",
    "            verbose=3\n",
    "        )\n",
    "\n",
    "        # output array is a vector of a single output, not 2d array of all outputs\n",
    "        y_output=y_train[:,index]\n",
    "\n",
    "        # run grid search\n",
    "        search.fit(X_train, y_output)\n",
    "        \n",
    "        # report results\n",
    "        print(\"Best CV score: %0.3f:\" % search.best_score_)\n",
    "        print(\"Best parameters:\",  search.best_params_, '\\n')\n",
    "        \n",
    "        # save results of each model to a dictionary\n",
    "        trained_models[model_name] = search \n",
    "\n",
    "    # save results from each output to a dictionary\n",
    "    trained_model_dictionary[output] = trained_models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# back up results from non-Bayesian models \n",
    "biomass\n",
    "\n",
    "nn\n",
    "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   4 out of  30 | elapsed:    1.4s remaining:    9.3s\n",
    "[Parallel(n_jobs=30)]: Done  15 out of  30 | elapsed:    2.2s remaining:    2.2s\n",
    "[Parallel(n_jobs=30)]: Done  26 out of  30 | elapsed:    3.5s remaining:    0.5s\n",
    "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:    4.2s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "\n",
    "Best CV score: 0.470:\n",
    "Best parameters: {'activation': 'logistic', 'max_iter': 400} \n",
    "\n",
    "svm_rbf\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.125:\n",
    "Best parameters: {'C': 1, 'epsilon': 0.1} \n",
    "\n",
    "rf\n",
    "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
    "Best CV score: 0.319:\n",
    "Best parameters: {'max_depth': 2, 'n_estimators': 10} \n",
    "\n",
    "en\n",
    "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
    "  \"avoid this warning.\", FutureWarning)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done  21 out of  80 | elapsed:    0.1s remaining:    0.3s\n",
    "[Parallel(n_jobs=30)]: Done  48 out of  80 | elapsed:    0.1s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  80 out of  80 | elapsed:    0.1s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done  31 out of  90 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  90 out of  90 | elapsed:    0.1s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "\n",
    "Best CV score: 0.261:\n",
    "Best parameters: {'alpha': 0.0001, 'l1_ratio': 0.1} \n",
    "\n",
    "lasso\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.260:\n",
    "Best parameters: {'alpha': 0.0001} \n",
    "\n",
    "knn\n",
    "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
    "Best CV score: 0.837:\n",
    "Best parameters: {'algorithm': 'ball_tree', 'leaf_size': 4, 'n_neighbors': 4, 'weights': 'distance'} \n",
    "\n",
    "ethanol\n",
    "\n",
    "nn\n",
    "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Done   4 out of  30 | elapsed:   11.4s remaining:  1.2min\n",
    "[Parallel(n_jobs=30)]: Done  15 out of  30 | elapsed:   13.0s remaining:   13.0s\n",
    "[Parallel(n_jobs=30)]: Done  26 out of  30 | elapsed:   14.5s remaining:    2.2s\n",
    "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:   14.8s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
    "  % self.max_iter, ConvergenceWarning)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.1s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
    "  \"avoid this warning.\", FutureWarning)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
    "\n",
    "Best CV score: 0.895:\n",
    "Best parameters: {'activation': 'tanh', 'max_iter': 400} \n",
    "\n",
    "svm_rbf\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.294:\n",
    "Best parameters: {'C': 1, 'epsilon': 1} \n",
    "\n",
    "rf\n",
    "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
    "Best CV score: 0.686:\n",
    "Best parameters: {'max_depth': 2, 'n_estimators': 10} \n",
    "\n",
    "en\n",
    "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done  21 out of  80 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  48 out of  80 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  80 out of  80 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7097.125190323121, tolerance: 5.923503688869955\n",
    "  positive)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "\n",
    "Best CV score: 0.552:\n",
    "Best parameters: {'alpha': 0.001, 'l1_ratio': 0.1} \n",
    "\n",
    "lasso\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.552:\n",
    "Best parameters: {'alpha': 0.01} \n",
    "\n",
    "knn\n",
    "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
    "Best CV score: 0.933:\n",
    "Best parameters: {'algorithm': 'ball_tree', 'leaf_size': 4, 'n_neighbors': 4, 'weights': 'distance'} \n",
    "\n",
    "acetate\n",
    "\n",
    "nn\n",
    "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Done  31 out of  90 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  90 out of  90 | elapsed:    0.1s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   4 out of  30 | elapsed:   10.9s remaining:  1.2min\n",
    "[Parallel(n_jobs=30)]: Done  15 out of  30 | elapsed:   12.6s remaining:   12.6s\n",
    "[Parallel(n_jobs=30)]: Done  26 out of  30 | elapsed:   14.1s remaining:    2.2s\n",
    "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:   14.3s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
    "  % self.max_iter, ConvergenceWarning)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.1s remaining:    0.3s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.1s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
    "  \"avoid this warning.\", FutureWarning)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
    "\n",
    "Best CV score: 0.850:\n",
    "Best parameters: {'activation': 'tanh', 'max_iter': 400} \n",
    "\n",
    "svm_rbf\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: -0.043:\n",
    "Best parameters: {'C': 1, 'epsilon': 1} \n",
    "\n",
    "rf\n",
    "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
    "Best CV score: 0.621:\n",
    "Best parameters: {'max_depth': 2, 'n_estimators': 10} \n",
    "\n",
    "en\n",
    "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
    "Best CV score: 0.480:\n",
    "Best parameters: {'alpha': 0.1, 'l1_ratio': 0.1} \n",
    "\n",
    "lasso\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.480:\n",
    "Best parameters: {'alpha': 0.1} \n",
    "\n",
    "knn\n",
    "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done  21 out of  80 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  48 out of  80 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  80 out of  80 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42000.21451921737, tolerance: 27.122111107765193\n",
    "  positive)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done  31 out of  90 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  90 out of  90 | elapsed:    0.1s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "\n",
    "Best CV score: 0.819:\n",
    "Best parameters: {'algorithm': 'ball_tree', 'leaf_size': 4, 'n_neighbors': 4, 'weights': 'distance'} \n",
    "\n",
    "butanol\n",
    "\n",
    "nn\n",
    "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Done   4 out of  30 | elapsed:    9.6s remaining:  1.0min\n",
    "[Parallel(n_jobs=30)]: Done  15 out of  30 | elapsed:   12.3s remaining:   12.3s\n",
    "[Parallel(n_jobs=30)]: Done  26 out of  30 | elapsed:   13.7s remaining:    2.1s\n",
    "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:   14.2s finished\n",
    "\n",
    "Best CV score: 0.968:\n",
    "Best parameters: {'activation': 'tanh', 'max_iter': 400} \n",
    "\n",
    "svm_rbf\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.643:\n",
    "Best parameters: {'C': 1, 'epsilon': 0.1} \n",
    "\n",
    "rf\n",
    "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.1s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
    "  \"avoid this warning.\", FutureWarning)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done  21 out of  80 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  48 out of  80 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  80 out of  80 | elapsed:    0.1s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "\n",
    "Best CV score: 0.684:\n",
    "Best parameters: {'max_depth': 2, 'n_estimators': 10} \n",
    "\n",
    "en\n",
    "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
    "Best CV score: 0.743:\n",
    "Best parameters: {'alpha': 0.0001, 'l1_ratio': 0.1} \n",
    "\n",
    "lasso\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.743:\n",
    "Best parameters: {'alpha': 0.0001} \n",
    "\n",
    "knn\n",
    "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Done  31 out of  90 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  62 out of  90 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  90 out of  90 | elapsed:    0.1s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "\n",
    "Best CV score: 0.979:\n",
    "Best parameters: {'algorithm': 'ball_tree', 'leaf_size': 4, 'n_neighbors': 2, 'weights': 'distance'} \n",
    "\n",
    "butyrate\n",
    "\n",
    "nn\n",
    "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Done   4 out of  30 | elapsed:    9.2s remaining:   59.7s\n",
    "[Parallel(n_jobs=30)]: Done  15 out of  30 | elapsed:   12.8s remaining:   12.8s\n",
    "[Parallel(n_jobs=30)]: Done  26 out of  30 | elapsed:   13.7s remaining:    2.1s\n",
    "[Parallel(n_jobs=30)]: Done  30 out of  30 | elapsed:   14.2s finished\n",
    "\n",
    "Best CV score: 0.902:\n",
    "Best parameters: {'activation': 'tanh', 'max_iter': 400} \n",
    "\n",
    "svm_rbf\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.650:\n",
    "Best parameters: {'C': 1, 'epsilon': 0.1} \n",
    "\n",
    "rf\n",
    "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.1s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
    "  \"avoid this warning.\", FutureWarning)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
    "\n",
    "Best CV score: 0.438:\n",
    "Best parameters: {'max_depth': 2, 'n_estimators': 10} \n",
    "\n",
    "en\n",
    "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
    "Best CV score: 0.406:\n",
    "Best parameters: {'alpha': 0.0001, 'l1_ratio': 0.1} \n",
    "\n",
    "lasso\n",
    "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
    "Best CV score: 0.406:\n",
    "Best parameters: {'alpha': 0.0001} \n",
    "\n",
    "knn\n",
    "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
    "\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done  21 out of  80 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  48 out of  80 | elapsed:    0.1s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  80 out of  80 | elapsed:    0.1s finished\n",
    "/usr/local/share/jupyteruser/.pyenv/versions/biod_3.7/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.974590054853707, tolerance: 0.3975429358853114\n",
    "  positive)\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "[Parallel(n_jobs=30)]: Done   9 out of  40 | elapsed:    0.0s remaining:    0.1s\n",
    "[Parallel(n_jobs=30)]: Done  23 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  37 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
    "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
    "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
    "\n",
    "Best CV score: 0.918:\n",
    "Best parameters: {'algorithm': 'ball_tree', 'leaf_size': 4, 'n_neighbors': 4, 'weights': 'distance'} \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bayesian result\n",
    "\n",
    "biomass\n",
    "\n",
    "bayesian\n",
    "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
    "Best CV score: 0.261:\n",
    "Best parameters: {'alpha_1': 0.1, 'alpha_2': 1, 'lambda_1': 1, 'lambda_2': 1, 'n_iter': 300} \n",
    "\n",
    "ethanol\n",
    "\n",
    "bayesian\n",
    "\n",
    "Best CV score: 0.546:\n",
    "Best parameters: {'alpha_1': 1, 'alpha_2': 0.1, 'lambda_1': 0.1, 'lambda_2': 1, 'n_iter': 300} \n",
    "\n",
    "acetate\n",
    "\n",
    "bayesian\n",
    "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
    "Best CV score: 0.480:\n",
    "Best parameters: {'alpha_1': 1, 'alpha_2': 0.1, 'lambda_1': 0.1, 'lambda_2': 1, 'n_iter': 300} \n",
    "\n",
    "butanol\n",
    "\n",
    "bayesian\n",
    "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
    "Best CV score: 0.740:\n",
    "Best parameters: {'alpha_1': 1, 'alpha_2': 0.1, 'lambda_1': 0.1, 'lambda_2': 1, 'n_iter': 300} \n",
    "\n",
    "butyrate\n",
    "\n",
    "bayesian\n",
    "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
    "Best CV score: 0.404:\n",
    "Best parameters: {'alpha_1': 1, 'alpha_2': 0.1, 'lambda_1': 0.1, 'lambda_2': 1, 'n_iter': 300} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
